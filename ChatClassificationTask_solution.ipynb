{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlfJZFhBki59"
   },
   "source": [
    "# Тестовое задание на позицию DS'а"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZb-Vy_yki6A"
   },
   "source": [
    "## Описание датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiNPJcFBki6B"
   },
   "source": [
    "В этом задании предлагается классифицировать сообщения на предмет того, из какого чата они были взяты. Датасет представляет собой сообщения участников двух публичных чатов:\n",
    "* Чат по Python (label=0)\n",
    "* Чат по Data Science (label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSiAb4Bmki6B"
   },
   "source": [
    "## Описание задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QKiD80aki6B"
   },
   "source": [
    "Ваша задача:\n",
    "1. Сделать предобработку текстов\n",
    "2. Предложить модель классификации, метрики.\n",
    "3. Объяснить их выбор (достоинства/недостатки). \n",
    "4. Сделать выводы по работе модели(ей) (достоинства/недостатки), а также проблемы, с которыми вы или ваша модель столкнулась.\n",
    "\n",
    "Было бы интересно посмотреть не только на финальное решение, но и на эксперименты (даже провальные). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ozF76zmki6G"
   },
   "source": [
    "Итоговую модель далее нужно:\n",
    "1. Обернуть в класс\n",
    "2. Развернуть модель как REST API\n",
    "3. Предоставить инструкцию что нужно сделать чтобы развернуть апи модели у себя на компьютере "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7skFhwFEki6C"
   },
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JaxKb7yjlrgc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "ZXcV3yiLki6C",
    "outputId": "6ce47555-fdcc-4583-fb6e-de13b3949f47"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/bhwblzw50zq_dtfl9p7kdbq00000gn/T/ipykernel_2839/4054579702.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11181</th>\n",
       "      <td>Какая разница? Я бы тогда больше занимался АСМ или тем же ML, имел бы свободное время, мог бы выбирать среди большего количества направлений, а не так, что я гребу на галере, а потом по ночам решаю mlbootcamp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>а в nginx для каждой страницы нужно прописывать location?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9532</th>\n",
       "      <td>Я хозяин i3, поэтому у меня одна модель, а не ансамбль, и я оставляю GridSearch на ночь)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>ну если ты вундеркиндом был я за тебя рад. А вообще один из кор разработиков говорил что что-то будут менять с докой</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Так у тебя новый не знает о старых, для него ID пойдут с нуля</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                   text  \\\n",
       "11181  Какая разница? Я бы тогда больше занимался АСМ или тем же ML, имел бы свободное время, мог бы выбирать среди большего количества направлений, а не так, что я гребу на галере, а потом по ночам решаю mlbootcamp   \n",
       "4706   а в nginx для каждой страницы нужно прописывать location?                                                                                                                                                          \n",
       "9532   Я хозяин i3, поэтому у меня одна модель, а не ансамбль, и я оставляю GridSearch на ночь)                                                                                                                           \n",
       "11846  ну если ты вундеркиндом был я за тебя рад. А вообще один из кор разработиков говорил что что-то будут менять с докой                                                                                               \n",
       "32     Так у тебя новый не знает о старых, для него ID пойдут с нуля                                                                                                                                                      \n",
       "\n",
       "       label  \n",
       "11181  1      \n",
       "4706   0      \n",
       "9532   1      \n",
       "11846  0      \n",
       "32     1      "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDCETiU4ki6E",
    "outputId": "1cbf10a4-8bf2-428d-8376-060f569c9f43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12404, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIysKbhiki6F"
   },
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3Zza0NplAC5",
    "outputId": "e72352fc-141b-4e7b-9784-6b664f04c1c9"
   },
   "outputs": [],
   "source": [
    "# ! pip3 install nltk\n",
    "# ! pip3 install pymorphy2\n",
    "# ! pip3 install stop-words\n",
    "# ! pip3 install pymystem3\n",
    "# ! pip3 install catboost\n",
    "# ! pip3 install gensim\n",
    "# ! pip3 install flask\n",
    "# ! pip3 install flask_restful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrBB44_a8Cdm"
   },
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jqtr6v9x1K4T",
    "outputId": "b82ab660-50b9-4c30-a479-5653d081b373"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ilya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "_create_unverified_https_context = ssl._create_unverified_context\n",
    "ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EpQ-017j1PIt"
   },
   "outputs": [],
   "source": [
    "# заготовим стоп-слова\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "russian_stopwords = stopwords.words('russian')\n",
    "russian_stopwords_2 = get_stop_words('russian')\n",
    "\n",
    "russian_stopwords  = list(set(russian_stopwords) | set(russian_stopwords_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PU9Rtyrqki6E"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# удалим знаки пунктуации и числа\n",
    "deleted_symols = punctuation + '0123456789'\n",
    "func = lambda text: ''.join([char for char in text if str(char) not in deleted_symols])\n",
    "df['text_prepared'] = df['text'].apply(func)\n",
    "\n",
    "# удалим стоп-слова\n",
    "func = lambda text: ' '.join([word for word in text.split(' ') if word not in russian_stopwords])\n",
    "df['text_prepared'] = df['text_prepared'].str.lower().apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "AZqz_f1N3M98",
    "outputId": "522456a2-78dd-4e25-bd1a-62e609a4e80b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_prepared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>если у тебя нет верхнего предела, фиксед поинт это проблема</td>\n",
       "      <td>1</td>\n",
       "      <td>верхнего предела фиксед поинт проблема</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ага или паркинг пула подобных сайтов и сравнение цен и др параметров</td>\n",
       "      <td>0</td>\n",
       "      <td>ага паркинг пула подобных сайтов сравнение цен др параметров</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>я думаю, что скор должен быть близок к максимуму.</td>\n",
       "      <td>1</td>\n",
       "      <td>думаю скор должен близок максимуму</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ты делаешь ту задачу с парсингом 20к страниц?) без прокси и без многопоточности уже бы спарсил)</td>\n",
       "      <td>0</td>\n",
       "      <td>делаешь задачу парсингом страниц прокси многопоточности спарсил</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>То есть ты больше веришь, что я реально могу попасть в топ, чем в то, что рандом сейчас лучше моделей?)</td>\n",
       "      <td>1</td>\n",
       "      <td>веришь реально могу попасть топ рандом моделей</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text  \\\n",
       "0  если у тебя нет верхнего предела, фиксед поинт это проблема                                               \n",
       "1  Ага или паркинг пула подобных сайтов и сравнение цен и др параметров                                      \n",
       "2  я думаю, что скор должен быть близок к максимуму.                                                         \n",
       "3  Ты делаешь ту задачу с парсингом 20к страниц?) без прокси и без многопоточности уже бы спарсил)           \n",
       "4  То есть ты больше веришь, что я реально могу попасть в топ, чем в то, что рандом сейчас лучше моделей?)   \n",
       "\n",
       "   label                                                    text_prepared  \n",
       "0  1      верхнего предела фиксед поинт проблема                           \n",
       "1  0      ага паркинг пула подобных сайтов сравнение цен др параметров     \n",
       "2  1      думаю скор должен близок максимуму                               \n",
       "3  0      делаешь задачу парсингом страниц прокси многопоточности спарсил  \n",
       "4  1      веришь реально могу попасть топ рандом моделей                   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MxvudPcrk9r3"
   },
   "outputs": [],
   "source": [
    "# from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "# # лематизируем слова\n",
    "# all_word_str = \" \".join(df[\"text_prepared\"])\n",
    "# all_word_list = all_word_str.split()\n",
    "# all_unique_word = np.unique(all_word_list)\n",
    "# lemmatized_word_dict = {}\n",
    "# lemmatizer = MorphAnalyzer()\n",
    "\n",
    "# for word in all_unique_word:\n",
    "#     lemmatized_word_dict[word] = lemmatizer.normal_forms(word)[0]\n",
    "# func = lambda text: ' '.join([lemmatized_word_dict[word] for word in text.split()])\n",
    "\n",
    "\n",
    "# df['text_prepared'] = df['text_prepared'].apply(func)\n",
    "\n",
    "\n",
    "\n",
    "## смотрел рандомные примеры: местами не все глаголы лематизировались, особенно англицизимы\n",
    "## попробовал другой, стало получше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NFjbE5qM06AW"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "mystem = Mystem() \n",
    "func = lambda text: ''.join(mystem.lemmatize(text)).strip()\n",
    "df['text_prepared'] = df['text_prepared'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "h4WcQFtcsOyc",
    "outputId": "8709325a-cc08-41f1-cf72-3df1e5639f12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_prepared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>если у тебя нет верхнего предела, фиксед поинт это проблема</td>\n",
       "      <td>1</td>\n",
       "      <td>верхний предел фикседой поинт проблема</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ага или паркинг пула подобных сайтов и сравнение цен и др параметров</td>\n",
       "      <td>0</td>\n",
       "      <td>ага паркинг пул подобный сайт сравнение цена др параметр</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>я думаю, что скор должен быть близок к максимуму.</td>\n",
       "      <td>1</td>\n",
       "      <td>думать скорый должный близкий максимум</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ты делаешь ту задачу с парсингом 20к страниц?) без прокси и без многопоточности уже бы спарсил)</td>\n",
       "      <td>0</td>\n",
       "      <td>делать задача парсинг страница прокси многопоточность спарсить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>То есть ты больше веришь, что я реально могу попасть в топ, чем в то, что рандом сейчас лучше моделей?)</td>\n",
       "      <td>1</td>\n",
       "      <td>верить реально мочь попадать топ ранд модель</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text  \\\n",
       "0  если у тебя нет верхнего предела, фиксед поинт это проблема                                               \n",
       "1  Ага или паркинг пула подобных сайтов и сравнение цен и др параметров                                      \n",
       "2  я думаю, что скор должен быть близок к максимуму.                                                         \n",
       "3  Ты делаешь ту задачу с парсингом 20к страниц?) без прокси и без многопоточности уже бы спарсил)           \n",
       "4  То есть ты больше веришь, что я реально могу попасть в топ, чем в то, что рандом сейчас лучше моделей?)   \n",
       "\n",
       "   label                                                   text_prepared  \n",
       "0  1      верхний предел фикседой поинт проблема                          \n",
       "1  0      ага паркинг пул подобный сайт сравнение цена др параметр        \n",
       "2  1      думать скорый должный близкий максимум                          \n",
       "3  0      делать задача парсинг страница прокси многопоточность спарсить  \n",
       "4  1      верить реально мочь попадать топ ранд модель                    "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHMH7VAqNJoo"
   },
   "source": [
    "## Векторизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bHFfBN9bSZk5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text_prepared']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n",
    "                                                    test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynpYPH4nO0Ul"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "827ZWyubmTI8",
    "outputId": "ec2bdac0-6a7e-42f3-f9db-0c3928f0e4bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9923, 1166)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# начнем с классики\n",
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=10, \n",
    "    max_df=50, \n",
    "    ngram_range=(1, 5)\n",
    ")\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeIkOjxZO2wT"
   },
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "O6_f_fmMO4Hh"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# попробуем чуть более-продвинутую векторизацию текста\n",
    "# эмбеддинги слов просто усредним\n",
    "docs = [doc.split() for doc in X_train]\n",
    "w2v = Word2Vec(sentences=docs, vector_size=100, window=4, sg=0, min_count=1, epochs=100, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_trans_word(word, w2v=w2v):\n",
    "    '''\n",
    "    вспомогательная функция для обработки слов, которых нет в словаре\n",
    "    '''\n",
    "    try:\n",
    "        return w2v.wv.get_vector(word)\n",
    "    except:\n",
    "        return np.zeros(100)\n",
    "\n",
    "def w2v_trans_doc(doc, w2v=w2v):\n",
    "    '''\n",
    "    функция для преобразования pd.Series в вектор w2v через метод apply\n",
    "    '''\n",
    "    return np.mean([w2v_trans_word(word, w2v) for word in doc.split()], axis=0)\n",
    "    \n",
    "def w2v_vectorizer(X_test, w2v=w2v):\n",
    "    '''\n",
    "    функция для преобразования pd.Series в вектор w2v через метод apply,\n",
    "    а также для обработки ошибок сообщений, где оказались только стоп-слова\n",
    "    '''\n",
    "    return np.vstack([np.zeros(100) if np.isnan(np.std(doc)) else doc for doc in \n",
    "                     X_test.apply(w2v_trans_doc, w2v).tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WDHpNk6CWyjW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9923, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v = w2v_vectorizer(X_train)\n",
    "X_test_w2v = w2v_vectorizer(X_test)\n",
    "\n",
    "X_train_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qje0rz6ZQkYB"
   },
   "source": [
    "### doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MJf_RAjDKXF8"
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "\n",
    "# попробуем векторизацю документов целиком\n",
    "# усреднение после w2v может вызвать сильные искажения для длинных постов\n",
    "def tagged_document(list_of_list_of_words):\n",
    "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "        yield doc2vec.TaggedDocument(list_of_words, [i])\n",
    "\n",
    "data_for_training = list(tagged_document(docs))\n",
    "d2v_model = doc2vec.Doc2Vec(vector_size=100, min_count=1, epochs=100, seed=0)\n",
    "d2v_model.build_vocab(data_for_training)\n",
    "d2v_model.train(data_for_training, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLhd8PkBMCw2",
    "outputId": "b3cae0a1-7389-4bbd-edd2-62ff1d53fb4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9923, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_d2v = np.stack([d2v_model.infer_vector(doc.split()) for doc in X_train])\n",
    "X_test_d2v = np.stack([d2v_model.infer_vector(doc.split()) for doc in X_test])\n",
    "X_train_d2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7QOt-SWUhlp"
   },
   "source": [
    "# Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TUFcsvfZ69G"
   },
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DCy0sdd1mTs2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=3000, random_state=0) #, penalty='l1', C=1, solver='saga')\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "## чуть-чуть играл с отсевом признаков, инсайтов не было особо\n",
    "# k = clf.coef_.shape[1]\n",
    "# k_zero = (clf.coef_==0).sum()\n",
    "# print(f'{k_zero} из {k} коэффициентов занунилось')\n",
    "# print(f'осталось коэффициентов {k-k_zero}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1RAC8j4RVOOM"
   },
   "outputs": [],
   "source": [
    "Xs = [\n",
    "    [X_train_vec, X_test_vec],\n",
    "    [X_train_w2v, X_test_w2v],\n",
    "    [X_train_d2v, X_test_d2v],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bO77raoOV3h_"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "XsTuWk9AnsZM",
    "outputId": "80aa79b4-cf9a-4fed-96c8-32a1239368da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.775773</td>\n",
       "      <td>0.729141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.762068</td>\n",
       "      <td>0.762999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec</th>\n",
       "      <td>0.724781</td>\n",
       "      <td>0.737606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train      test\n",
       "TF-IDF    0.775773  0.729141\n",
       "word2vec  0.762068  0.762999\n",
       "doc2vec   0.724781  0.737606"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = []\n",
    "clfs = {}\n",
    "for i, preprocess in enumerate(Xs):\n",
    "    clf.fit(Xs[i][0], y_train)\n",
    "    clfs[i] = clf\n",
    "    acc.append([\n",
    "        accuracy_score(y_train, clf.predict(Xs[i][0])),\n",
    "        accuracy_score(y_test, clf.predict(Xs[i][1]))\n",
    "        ])\n",
    "    \n",
    "# результаты лог регрессии\n",
    "\n",
    "acc_clf = pd.DataFrame(acc, index=['TF-IDF', 'word2vec', 'doc2vec'], columns=['train', 'test'])\n",
    "acc_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uQaNbZae64p"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "B-PrtK2Ke8oY"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "scaler = StandardScaler(with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "C3aIC1VYe_x8",
    "outputId": "33f9d514-f4f2-487c-db48-4c0aa7da93f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.673687</td>\n",
       "      <td>0.641677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.761161</td>\n",
       "      <td>0.740830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec</th>\n",
       "      <td>0.653633</td>\n",
       "      <td>0.659815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train      test\n",
       "TF-IDF    0.673687  0.641677\n",
       "word2vec  0.761161  0.740830\n",
       "doc2vec   0.653633  0.659815"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = []\n",
    "for i, preprocess in enumerate(Xs):\n",
    "    scaler.fit(Xs[i][0])\n",
    "    knn.fit(scaler.transform(Xs[i][0]), y_train)\n",
    "    acc.append([\n",
    "        accuracy_score(y_train, knn.predict(scaler.transform(Xs[i][0]))),\n",
    "        accuracy_score(y_test, knn.predict(scaler.transform(Xs[i][1])))\n",
    "        ])\n",
    "    \n",
    "# результаты KNN\n",
    "\n",
    "acc_knn = pd.DataFrame(acc, index=['TF-IDF', 'word2vec', 'doc2vec'], columns=['train', 'test'])\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBU_cNvvZ9Je"
   },
   "source": [
    "## CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xV4OL-MfZLz-"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat = CatBoostClassifier(metric_period=500, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "YCCZ8MgiZPl2",
    "outputId": "e6bb1923-84e5-4550-e7aa-26212e33988e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.027447\n",
      "0:\tlearn: 0.6923653\ttotal: 66.2ms\tremaining: 1m 6s\n",
      "500:\tlearn: 0.5798352\ttotal: 4.54s\tremaining: 4.53s\n",
      "999:\tlearn: 0.5269313\ttotal: 9.09s\tremaining: 0us\n",
      "Learning rate set to 0.027447\n",
      "0:\tlearn: 0.6869225\ttotal: 8.69ms\tremaining: 8.68s\n",
      "500:\tlearn: 0.3777419\ttotal: 4.83s\tremaining: 4.82s\n",
      "999:\tlearn: 0.2714884\ttotal: 9.49s\tremaining: 0us\n",
      "Learning rate set to 0.027447\n",
      "0:\tlearn: 0.6905108\ttotal: 9.02ms\tremaining: 9.01s\n",
      "500:\tlearn: 0.4465834\ttotal: 4.55s\tremaining: 4.53s\n",
      "999:\tlearn: 0.3302244\ttotal: 9.11s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.763580</td>\n",
       "      <td>0.706973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.924720</td>\n",
       "      <td>0.778315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec</th>\n",
       "      <td>0.917364</td>\n",
       "      <td>0.732769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train      test\n",
       "TF-IDF    0.763580  0.706973\n",
       "word2vec  0.924720  0.778315\n",
       "doc2vec   0.917364  0.732769"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = []\n",
    "cats = {}\n",
    "for i, preprocess in enumerate(Xs):\n",
    "    cat.fit(Xs[i][0], y_train)\n",
    "    cats[i] = cat\n",
    "    acc.append([\n",
    "        accuracy_score(y_train, cat.predict(Xs[i][0])),\n",
    "        accuracy_score(y_test, cat.predict(Xs[i][1]))\n",
    "        ])\n",
    "    \n",
    "# результаты катбуста\n",
    "\n",
    "acc_cat = pd.DataFrame(acc, index=['TF-IDF', 'word2vec', 'doc2vec'], columns=['train', 'test'])\n",
    "acc_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70      1104\n",
      "           1       0.75      0.77      0.76      1377\n",
      "\n",
      "    accuracy                           0.73      2481\n",
      "   macro avg       0.73      0.73      0.73      2481\n",
      "weighted avg       0.73      0.73      0.73      2481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cat.predict(Xs[i][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7WwoRnAhkTf"
   },
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала был выбран простой классический подход, а именно TF-IDF для векторизации текста в связке с лог. регрессией. Уже он показал неплохое качество, однако далее была попытка его улучшить. Для векторизации были сделаны эмбеддинги с помощью word2vec, а затем и с помощью doc2vec. А в качестве альтернативных моделей были взяты KNN и градиентный бустинг. KNN выбран из той логики, что на стандартизованных эмбеддингах он может себя хорошо показать, а бустинг в целом часто хорошо себя показывает.\n",
    "\n",
    "В качестве метрики выбрана accuracy, поскольку классы сбалансированы. Полнота и точность по обоим классам была в целом сопоставима, поэтому accuracy для анализа достаточно. Пример с полнотой и точностью приведен для тестовой выборки у бустинга (по остальным экспериментам была похожая динамика).\n",
    "\n",
    "Как показали эксперименты, эмбеддинги word2vec оказались лучше эмбеддингов doc2vec, векторизация с помощью TF-IDF оказалась хуже всех. Динамика была схожа для всех моделей. Лучше всего себя показал себя бустинг, но лог. регрессия всего немного хуже, метод ближ. соседей значительно хуже обеих моделей.\n",
    "\n",
    "В качестве итоговой тем не менее выбрана лог. регрессия за счёт простоты и скорости предикта. Для векторизации взят word2vec.\n",
    "\n",
    "Ниже пара примеров с тем, как делается предсказание.\n",
    "\n",
    "---\n",
    "\n",
    "Для запуска api нужно установить requirements.\n",
    "\n",
    "Команда чтобы запустить апи: python api.py\n",
    "\n",
    "Деплой тут: http://127.0.0.1:5000/\n",
    "\n",
    "Примеры, чтобы потестить\n",
    "1. переменные аргументы функции класс лямбда\n",
    "2. логрег бустинг эмбединнги топ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "TVHcmOaIhOT-",
    "outputId": "066b6d95-8560-4f99-b28a-d2accac3a032",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.775773</td>\n",
       "      <td>0.729141</td>\n",
       "      <td>0.673687</td>\n",
       "      <td>0.641677</td>\n",
       "      <td>0.763580</td>\n",
       "      <td>0.706973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.762068</td>\n",
       "      <td>0.762999</td>\n",
       "      <td>0.761161</td>\n",
       "      <td>0.740830</td>\n",
       "      <td>0.924720</td>\n",
       "      <td>0.778315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec</th>\n",
       "      <td>0.724781</td>\n",
       "      <td>0.737606</td>\n",
       "      <td>0.653633</td>\n",
       "      <td>0.659815</td>\n",
       "      <td>0.917364</td>\n",
       "      <td>0.732769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LR                 KNN                  CB          \n",
       "             train      test     train      test     train      test\n",
       "TF-IDF    0.775773  0.729141  0.673687  0.641677  0.763580  0.706973\n",
       "word2vec  0.762068  0.762999  0.761161  0.740830  0.924720  0.778315\n",
       "doc2vec   0.724781  0.737606  0.653633  0.659815  0.917364  0.732769"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([acc_clf,acc_knn,acc_cat], keys=['LR', 'KNN', 'CB'], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним лог. рег\n",
    "final = clfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(final, f)\n",
    "    \n",
    "with open('w2v.pickle', 'wb') as f:\n",
    "    pickle.dump(w2v, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('w2v.pickle', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import prepare\n",
    "\n",
    "\n",
    "def get_pred(doc, w2v=w2v):\n",
    "    vec = w2v_vectorizer(pd.Series(doc), w2v)\n",
    "    proba = model.predict_proba(vec)[:,1][0]\n",
    "\n",
    "    if proba>0.5:\n",
    "        return f'Это чат по Data Science с вероятностью {round(proba*100)}% : \\t {doc}'\n",
    "    else:\n",
    "        return f'Это чат по Python с вероятностью {round((1-proba)*100)}% : \\t\\t {doc}'\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_simple = pd.Series([\n",
    "    'переменные аргументы функции класс лямбда',\n",
    "    'логрег бустинг эмбединнги топ'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Это чат по Python с вероятностью 100% : \t\t переменный аргумент функция класс лямбда\n",
      "Это чат по Data Science с вероятностью 100% : \t логрег бустинг эмбединнга топ\n"
     ]
    }
   ],
   "source": [
    "for x in X_test_simple:\n",
    "    print(get_pred(prepare(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.811px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
